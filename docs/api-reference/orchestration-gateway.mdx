---
title: "Orchestration Gateway"
description: "Compute and Deployment Management"
---

The Orchestration Gateway manages the lifecycle of model deployments.

## Deployments

### `GET /deployment/deployments`
List all active deployments across all compute pools.

<ParamField query="org_id" type="string">
  Filter by Organization ID.
</ParamField>

### `POST /deployment/deploy`
Create a new model deployment.

<ParamField body="model_name" type="string" required>
  Name of the model to deploy.
</ParamField>

<ParamField body="image" type="string" required>
  Docker image to use (e.g., `vllm/vllm-openai:latest`).
</ParamField>

<ParamField body="pool_id" type="string" required>
  Target Compute Pool ID.
</ParamField>

<ParamField body="replicas" type="integer">
  Number of replicas (default: 1).
</ParamField>

### `POST /deployment/terminate`
Terminate a running deployment (stops the containers/service).

<ParamField body="deployment_id" type="string" required>
  The ID of the deployment to stop.
</ParamField>

### `DELETE /deployment/delete/{deployment_id}`
Permanently remove a stopped or failed deployment record.

<ParamField path="deployment_id" type="string" required>
  The ID of the deployment to delete.
</ParamField>

## Logs

### `GET /deployment/logs/{deployment_id}`
Retrieve live logs for a specific deployment. Supports DePIN (IPFS) logs.

## Model Registry

### `POST /deployment/registerModel`
Register a new model configuration in the system.

<ParamField body="model_name" type="string" required>
  Unique identifier for the model.
</ParamField>

<ParamField body="backend" type="string" required>
  Inference backend (e.g., `vllm`, `ollama`).
</ParamField>

### `GET /deployment/getModel/{name}/{version}`
Get details for a registered model version.
